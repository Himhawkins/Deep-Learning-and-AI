# -*- coding: utf-8 -*-
"""Untitled.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zMhi1KAENS45SOe20y62hArHcT-d4-fR
"""

from google.colab import drive
drive.mount('/content/drive/')

import numpy as np
import tensorflow as tf
import pandas as pd
import math
tf.compat.v1.disable_eager_execution()

Y_test= []
Y_train=[]
train_size=1193
data_read = pd.read_excel('/content/drive/My Drive/DL/labels.xls', header=None)
for i in range(len(data_read)):
  if i<train_size:
    Y_train.append(data_read[1][i])
  else:
    Y_test.append(data_read[1][i])
Y_train=np.reshape((Y_train+Y_train),np.shape(Y_train+Y_train))  
Y_test=np.reshape(Y_test,np.shape(Y_test))
#Hot encoding

Y_train=tf.one_hot(Y_train,10,axis=0)
Y_test=tf.one_hot(Y_test,10,axis=0)
print(data_read)
print(Y_test.shape)
print(Y_train.shape)
print(type(Y_train))

import os
import cv2
import matplotlib.pyplot as plt
path='/content/drive/My Drive/DL/'

train1 = []
train2= [] #inverted set
test = []
#for image in os.listdir(path):
#inerting and dublicating data
for i,image in enumerate(data_read[0]):
  image = cv2.imread(os.path.join(path,(image+'.jpg')),0)
  if image is not None :
    image = cv2.resize(image,(28,28))
  if i<train_size:
    train1.append(np.reshape(image,-1))
    train2.append(np.reshape((255-image),-1))
  else:
    test.append((np.reshape(image,-1)))

train=np.reshape((train1+train2),np.shape(train1+train2)).T/255  #normalisation
print(train.shape)
test=np.reshape((test),np.shape(test)).T/255 #normalisation #reshapingprint(test.shape)

def mini_batch(X,Y,batch_size=64,seed=0):
  #np.random.seed(seed)           
  m = X.shape[1]                  
  mini_batches = []
  permutation = list(np.random.permutation(m))
  shuffled_X = X[:, permutation]
  shuffled_Y = Y[:, permutation]
  no_mb=math.floor(m/batch_size)
  for k in range(0,no_mb):
    mb_X=shuffled_X[:,k*batch_size:(k+1)*batch_size]
    mb_Y=shuffled_Y[:,k*batch_size:(k+1)*batch_size]
    mb=(mb_X,mb_Y)
    mini_batches.append(mb)
  if (m%batch_size!=0):
    mb_X=shuffled_X[:,no_mb*batch_size:m]
    mb_Y=shuffled_Y[:,no_mb*batch_size:m]
    mb=(mb_X,mb_Y)
    mini_batches.append(mb)

  return mini_batches

def init_parameters(X,shape):
  parameters={}
  arr=[X.shape[0]]+shape
  
  for i in range(1,(len(arr))):
    #regularizer = tf.compat.v1.contrib.layers.l2_regularizer(scale=0.1) 

    parameters['W'+str(i)]= tf.Variable(tf.initializers.GlorotNormal()(shape=[arr[i],arr[i-1]]))
    parameters['b'+str(i)]= tf.Variable(tf.zeros_initializer()(shape=[arr[i],1]))
    

  return parameters

def forward_pass(X,parameters):
  Z=X
  for i in range(int(len(parameters)/2)):
    Z= tf.matmul(parameters['W'+str(i+1)],Z)+parameters['b'+str(i+1)]
    if i!= (len(parameters)/2-1):
      Z= tf.nn.relu(Z)
  return Z

def model(train_X,train_Y,test_X,test_Y,shape,learning_rate=0.0002,num_epochs=250,batch_size=64,print_cost = True):

  X= tf.compat.v1.placeholder(tf.float32,[train_X.shape[0],None])
  Y= tf.compat.v1.placeholder(tf.float32,[train_Y.shape[0],None])
  costs = [] 
  parameters=init_parameters(X, shape= shape)
  print(parameters)
  z= forward_pass(X, parameters)
  Yt=tf.transpose(Y)
  zt=tf.transpose(z)
  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=zt, labels=Yt))
  optimizer= tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(cost)
  init = tf.compat.v1.global_variables_initializer()
  
  with tf.compat.v1.Session() as sess:
    sess.run(init)
    
    for epoch in range(num_epochs):
      epoch_cost = 0.
      minibatches=mini_batch(train_X,sess.run(train_Y))
      for minibatch in minibatches:
        (mb_X,mb_Y) = minibatch
        _,mb_cost = sess.run([optimizer,cost],feed_dict={X:mb_X,Y:mb_Y})
        epoch_cost+=mb_cost/len(minibatches)
      if print_cost == True and epoch % 100 == 0:
        print ("Cost after epoch %i: %f" % (epoch, epoch_cost))
      if print_cost == True and epoch % 5 == 0:
        costs.append(epoch_cost)
        # plot the cost
    plt.plot(np.squeeze(costs))
    plt.ylabel('cost')
    plt.xlabel('iterations (per tens)')
    plt.title("Learning rate =" + str(learning_rate))
    plt.show()

    # lets save the parameters in a variable
    parameters = sess.run(parameters)
    print ("Parameters have been trained!")

    # Calculate the correct predictions
    correct_prediction = tf.equal(tf.argmax(z), tf.argmax(Y))

    # Calculate accuracy on the test set
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))

    print ("Train Accuracy:", accuracy.eval({X: train_X, Y: sess.run( train_Y)}))
    print ("Test Accuracy:", accuracy.eval({X: test_X, Y: sess.run(test_Y)}))
    
    return parameters

shape=[300,150,100,10]

parameters = model(train, Y_train, test, Y_test,shape)



